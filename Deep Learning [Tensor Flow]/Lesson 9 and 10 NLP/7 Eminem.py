# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RNaxszKNZQyrvsKD3D6P_7SM-0rxVMD6
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

import string
import numpy as np
import pandas as pd


# Eminem lyrics https://www.kaggle.com/thaddeussegura/eminem-lyrics-from-all-albums

from urllib.request import urlopen

data = urlopen('https://storage.googleapis.com/kagglesdsdata/datasets/835677/1426970/eminem_lyrics/ALL_eminem.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20201003%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20201003T224604Z&X-Goog-Expires=259199&X-Goog-SignedHeaders=host&X-Goog-Signature=03c848c521e5eda4ec0f9c3637972f5bf03f5e6adcd3e55782949a96d2617702872fa028af06ccf686bb40b61bb5cb38846bad3ffe0279ae1931272e10e0049d792a338b8ee2d313249d01a2875c918451402f5a6b96295d7e8d2e1ca1328016529dbb2a1d2d3105a9690f454b2f0b966539b5b9418c7f3d18228d8aa05fcc9ee6acae17634a2e075ed38d9a5376067ac8766da6519752f6a0a50f7e24e7a2a7fe186acecad46cba7c74f7040905b6c051bbf25182759dd3e4a292b1173f16fe315207a71e66a3d3fa19d6555dc95d3ca63a9a0aaee58d874eca3b06fe77b17521fb36855dbb6c7b6b3383dc3bdc86e9432402dbbf48b79f3595d2e0ca2f7c93').read().decode('utf-8')
print(data[:11])
print(len(data))

# split
text = data.split()
print(text[:10])

# remove puctuation, make all lowercase
dataset = []
import re
for s in text:
    s = re.sub(r'[^\w\s]','',s).lower()
    dataset.append(s)
print(dataset[:10])
print(len(dataset))


def tokenize_corpus(corpus, num_words=-1):
  # Fit a Tokenizer on the corpus
  if num_words > -1:
    tokenizer = Tokenizer(num_words=num_words)
  else:
    tokenizer = Tokenizer()
  tokenizer.fit_on_texts(corpus)
  return tokenizer

# Tokenize the corpus
tokenizer = tokenize_corpus(dataset)

total_words = len(tokenizer.word_index) + 1

print(tokenizer.word_index)
print(total_words)

token_list = tokenizer.texts_to_sequences(dataset[:10])



# get inputs and outputs
input_data = []
labels = []
for i in range(50000):
    tokens = np.array(sum(tokenizer.texts_to_sequences(dataset[i:i+11]), []))
    input_data.append(tokens[:-1])
    labels.append(tokens[-1])

input_data = np.asarray(input_data)
padded = pad_sequences(input_data, maxlen=10, padding="pre")
labels = np.array(labels)

#print(padded)
#print(labels)

# One-hot encode the labels
one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional

model = Sequential()
model.add(Embedding(total_words, 64, input_length=10))
model.add(Bidirectional(LSTM(32)))
model.add(Dense(total_words, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(padded, one_hot_labels, epochs=30, verbose=1)

import matplotlib.pyplot as plt

def plot_graphs(history, string):
  plt.plot(history.history[string])
  plt.xlabel("Epochs")
  plt.ylabel(string)
  plt.show()

plot_graphs(history, 'accuracy')

seed_text = "im feeling chills getting these bills still while having meal"
next_words = 100
  
for _ in range(next_words):
	token_list = tokenizer.texts_to_sequences([seed_text])[0]
	token_list = pad_sequences([token_list], maxlen=20, padding='pre')
	predicted = np.argmax(model.predict(token_list), axis=-1)
	output_word = ""
	for word, index in tokenizer.word_index.items():
		if index == predicted:
			output_word = word
			break
	seed_text += " " + output_word
print(seed_text)

seed_text = "im feeling chills getting these bills still while having meal"
next_words = 100
  
for _ in range(next_words):
  token_list = tokenizer.texts_to_sequences([seed_text])[0]
  token_list = pad_sequences([token_list], maxlen=10, padding='pre')
  predicted_probs = model.predict(token_list)[0]
  predicted = np.random.choice([x for x in range(len(predicted_probs))],
                               p=predicted_probs)
  output_word = ""
  for word, index in tokenizer.word_index.items():
    if index == predicted:
      output_word = word
      break
  seed_text += " " + output_word
print(seed_text)